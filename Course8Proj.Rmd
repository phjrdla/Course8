---
title: "Course8ML"
author: "P.Briens"
date: "February 11, 2018"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(ggplot2)
library(GGally)
library(caret)
library(doParallel)
library(rattle)
library(grid)
library(AppliedPredictiveModeling)
```

# Purpose
Fitness wearables can be used to track physical activity as they provide plenty of data originating from their accelerometers and sensors. 
In this study one is using a dataset (thanks to the HAR project http://groupware.les.inf.puc-rio.br/har ) with 5 classes (sitting-down, standing-up, standing, walking, and sitting) collected from several people working out in a controlled way.
Once an acceptable prediction model is identified/obtained it will be applied to 20 different test cases to figure out which activities were performed.

# Load training and test cases data (from working directory)
```{r Load}
training_raw <- read.csv("pml-training.csv", stringsAsFactors=F, na.strings = c("", "NA", "#DIV/0!"))
testcases_raw  <- read.csv("pml-testing.csv", stringsAsFactors=F, na.strings = c("", "NA", "#DIV/0!"))
names(training_raw)
names(testcases_raw)
```

# Quick summary for training dataset
1. Number of observations and variables
2. Number of observations / classe
3. Propertion of observations / classe
4. Number of observations / person / classe
```{r Summary}
dim(training_raw)
table(training_raw$classe)
prop.table(table(training_raw$classe))
table(training_raw$user_name,training_raw$classe )
```

# Data pre-processing
All calculated variables such as average, standard deviation, min, max, total etc ... and variables not useful for prediction are deleted.

## remove columns
data frames training_df and testcases_df created for training and testcases data
```{r cols2keep}
cols2remove <- "X|user_name|cvtd_timestamp|problem_id|var|raw|window|kurtosis|skewness|stddev|avg|total|max|min|problem_id"
cols2keep <- grep (cols2remove, names(training_raw),invert=TRUE)
training_df <- training_raw[, cols2keep]
cols2keep <- grep (cols2remove, names(testcases_raw),invert=TRUE)
testcases_df <- testcases_raw[, cols2keep]
```

## remove  columns with no values
1. reduced list of variables for training data 
  + classe is our model response variables
  + predictors will be found from all the remaining variables
2. reduced list of variables for test cases data
```{r remnovalues}
training_df <- training_df[, colSums(is.na(training_df)) == 0]
names(training_df)
testcases_df <- testcases_df[, colSums(is.na(testcases_df)) == 0]
```

# Basic exploratory analysis
Scatter and density distribution  plots are created for a subset of predictor variables typical of the training dataset.  
It appears that density distribution are not normal and scatter plots display a mix of complex clusters and others with no evident pattern.
```{r exploplots, echo=FALSE, cache=TRUE}
ggp11 <- ggpairs(data = training_df, columns=c(1:3))
ggp12 <- ggpairs(data = training_df, columns=c(13:15))
ggp13 <- ggpairs(data = training_df, columns=c(25:27))
ggp14 <- ggpairs(data = training_df, columns=c(37:39))
ggp31 <- ggpairs(data = training_df, columns=c(16:18))
ggp32 <- ggpairs(data = training_df, columns=c(19:21))
ggp33 <- ggpairs(data = training_df, columns=c(22:24))
ggp41 <- ggpairs(data = training_df, columns=c(31:33))

vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y)

grid.newpage()
pushViewport(viewport(layout = grid.layout(4, 2)))
print(ggp11, vp = vplayout(1, 1))
print(ggp12, vp = vplayout(1, 2))
print(ggp13, vp = vplayout(2, 1))
print(ggp14, vp = vplayout(2, 2))

print(ggp31, vp = vplayout(3, 1))
print(ggp32, vp = vplayout(3, 2))
print(ggp33, vp = vplayout(4, 1))
print(ggp41, vp = vplayout(4, 2))
```

# Prediction training and test sets preparation
Data frame training_df is used for model training and testing.  

* 80% of the dataset is allocated to model training, the 20% remaining to model testing.
    + observations for model training
    + observations for model testing

```{r setsprep}
set.seed(12345)
inTrain <- createDataPartition(training_df$classe, p=0.80, list=F)
trainDat <- training_df[inTrain, ]
testDat <- training_df[-inTrain, ]
dim(trainDat)
dim(testDat)
```

# Modelling
"caret" train package is used with random forest classification model limited to 250 trees and variable importance evaluation.  
"train" package is run in parallel.  

```{r modelling, cache=TRUE}
cl <- makeCluster(detectCores())
registerDoParallel(cl)
model_rf <- train(classe ~.,data=trainDat,method="rf", importance=TRUE, ntree=250)
stopCluster(cl)
```

## Random forest model details
+ Model details
+ Confusion matrix
+ Variables importance and plot

```{r details}
model_rf
rfImp <- varImp(model_rf, scale=F)
rfImp
plot(rfImp,top=15)
```

## Testing model accuracy
+ Confusion matrix predictions vs test data
+ Model accuracy is above 99%

```{r accuracy}
pred_rf <- predict(model_rf, testDat)
confusionMatrix(pred_rf, testDat$classe)
confusionMatrix(pred_rf, testDat$classe)$overall[1]
```

# Application to test cases
The random forest model evaluated in "Testing model accuracy" is applied to the 20 test cases.    
Test cases predicted Classes are listed.  

```{r predictions}
dim(testcases_df)
pred_20 <- predict(model_rf, testcases_df)
pred_20
```
